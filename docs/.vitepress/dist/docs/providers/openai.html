<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>OpenAI | Kelivo</title>
    <meta name="description" content="A LLM Chat Client">
    <meta name="generator" content="VitePress v1.6.4">
    <link rel="preload stylesheet" href="/assets/style.BDyx2dNJ.css" as="style">
    <link rel="preload stylesheet" href="/vp-icons.css" as="style">
    <script type="module" src="/assets/chunks/metadata.53a94b2c.js"></script>
    <script type="module" src="/assets/app.B3GvOBia.js"></script>
    <link rel="preload" href="/assets/inter-roman-latin.Di8DUHzh.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/assets/chunks/theme.DHKndhrI.js">
    <link rel="modulepreload" href="/assets/chunks/framework.IHAHILrl.js">
    <link rel="modulepreload" href="/assets/docs_providers_openai.md.DIL8A5mR.lean.js">
    <link rel="icon" type="image/png" href="/icon.png">
    <link rel="apple-touch-icon" href="/icon.png">
    <meta name="theme-color" content="#6C63FF">
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body><!--teleport start anchor--><div style="display:none;" class="tk-spotlight-hover tk-spotlight-hover__aside" aria-hidden="true" focusable="false"></div><!--teleport anchor-->
    <div id="app"><!--[--><!--v-if--><!--v-if--><!--v-if--><!--[--><!--v-if--><!----><!--v-if--><div class="tk-right-bottom-button tk-wallpaper-outside flx-column"><!--[--><!--]--><div title="ËøîÂõûÈ°∂ÈÉ®" class="tk-right-bottom-button__button back-top" style="--tk-progress:0;display:none;" role="button" aria-label="ËøîÂõûÈ°∂ÈÉ®" aria-valuenow="0" aria-valuemin="0" aria-valuemax="100"><span class="content">0</span></div><div title="ÂâçÂæÄËØÑËÆ∫" class="tk-right-bottom-button__button" role="button" aria-label="ÂâçÂæÄËØÑËÆ∫" style="display:none;"><i class="tk-icon" style="--icon-color-hover:var(--tk-theme-color);" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1024 1024">
    <path
      fill="currentColor"
      d="M273.536 736H800a64 64 0 0 0 64-64V256a64 64 0 0 0-64-64H224a64 64 0 0 0-64 64v570.88zM296 800 147.968 918.4A32 32 0 0 1 96 893.44V256a128 128 0 0 1 128-128h576a128 128 0 0 1 128 128v416a128 128 0 0 1-128 128z"
    ></path>
    <path
      fill="currentColor"
      d="M512 499.2a51.2 51.2 0 1 1 0-102.4 51.2 51.2 0 0 1 0 102.4zm192 0a51.2 51.2 0 1 1 0-102.4 51.2 51.2 0 0 1 0 102.4zm-384 0a51.2 51.2 0 1 1 0-102.4 51.2 51.2 0 0 1 0 102.4z"
    ></path>
  </svg></i></div><!--v-if--><!--[--><!--]--></div><!--]--><div class="Layout tk-layout" data-v-9a104c51><!--[--><!--]--><!--[--><span tabindex="-1" data-v-0b0ada53></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-0b0ada53>Skip to content</a><!--]--><!----><header class="VPNav" data-v-9a104c51 data-v-ae24b3ad><div class="VPNavBar" data-v-ae24b3ad data-v-6aa21345><div class="wrapper" data-v-6aa21345><div class="container" data-v-6aa21345><div class="title" data-v-6aa21345><div class="VPNavBarTitle has-sidebar" data-v-6aa21345 data-v-1168a8e4><a class="title" href="/" data-v-1168a8e4><!--[--><!--]--><!----><span data-v-1168a8e4>Kelivo</span><!--[--><!--]--></a></div></div><div class="content" data-v-6aa21345><div class="content-body" data-v-6aa21345><!--[--><!--]--><div class="VPNavBarSearch search" data-v-6aa21345><!----></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-6aa21345 data-v-dc692963><span id="main-nav-aria-label" class="visually-hidden" data-v-dc692963> Main Navigation </span><!--[--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/" tabindex="0" data-v-dc692963 data-v-e56f3d57><!--[--><span data-v-e56f3d57>Home</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/docs/getting-started/quick-start" tabindex="0" data-v-dc692963 data-v-e56f3d57><!--[--><span data-v-e56f3d57>Docs</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/download" tabindex="0" data-v-dc692963 data-v-e56f3d57><!--[--><span data-v-e56f3d57>Download</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/privacy-policy" tabindex="0" data-v-dc692963 data-v-e56f3d57><!--[--><span data-v-e56f3d57>Privacy Policy</span><!--]--></a><!--]--><!--]--></nav><div class="VPFlyout VPNavBarTranslations translations" data-v-6aa21345 data-v-88af2de4 data-v-cf11d7a2><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="Change language" data-v-cf11d7a2><span class="text" data-v-cf11d7a2><span class="vpi-languages option-icon" data-v-cf11d7a2></span><!----><span class="vpi-chevron-down text-icon" data-v-cf11d7a2></span></span></button><div class="menu" data-v-cf11d7a2><div class="VPMenu" data-v-cf11d7a2 data-v-b98bc113><!----><!--[--><!--[--><div class="items" data-v-88af2de4><p class="title" data-v-88af2de4>English</p><!--[--><div class="VPMenuLink" data-v-88af2de4 data-v-35975db6><a class="VPLink link" href="/zh/docs/providers/openai" data-v-35975db6><!--[--><span data-v-35975db6>ÁÆÄ‰Ωì‰∏≠Êñá</span><!--]--></a></div><!--]--></div><!--]--><!--]--></div></div></div><div class="VPNavBarAppearance appearance" data-v-6aa21345 data-v-6c893767><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-6c893767 data-v-5337faa4 data-v-1d5665e3><span class="check" data-v-1d5665e3><span class="icon" data-v-1d5665e3><!--[--><span class="vpi-sun sun" data-v-5337faa4></span><span class="vpi-moon moon" data-v-5337faa4></span><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-6aa21345 data-v-0394ad82 data-v-7bc22406><!--[--><a class="VPSocialLink no-icon" href="https://github.com/Chevey339/kelivo" aria-label="github" target="_blank" rel="noopener" data-v-7bc22406 data-v-bd121fe5><span class="vpi-social-github"></span></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-6aa21345 data-v-bb2aa2f0 data-v-cf11d7a2><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-cf11d7a2><span class="vpi-more-horizontal icon" data-v-cf11d7a2></span></button><div class="menu" data-v-cf11d7a2><div class="VPMenu" data-v-cf11d7a2 data-v-b98bc113><!----><!--[--><!--[--><div class="group translations" data-v-bb2aa2f0><p class="trans-title" data-v-bb2aa2f0>English</p><!--[--><div class="VPMenuLink" data-v-bb2aa2f0 data-v-35975db6><a class="VPLink link" href="/zh/docs/providers/openai" data-v-35975db6><!--[--><span data-v-35975db6>ÁÆÄ‰Ωì‰∏≠Êñá</span><!--]--></a></div><!--]--></div><div class="group" data-v-bb2aa2f0><div class="item appearance" data-v-bb2aa2f0><p class="label" data-v-bb2aa2f0>Appearance</p><div class="appearance-action" data-v-bb2aa2f0><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-bb2aa2f0 data-v-5337faa4 data-v-1d5665e3><span class="check" data-v-1d5665e3><span class="icon" data-v-1d5665e3><!--[--><span class="vpi-sun sun" data-v-5337faa4></span><span class="vpi-moon moon" data-v-5337faa4></span><!--]--></span></span></button></div></div></div><div class="group" data-v-bb2aa2f0><div class="item social-links" data-v-bb2aa2f0><div class="VPSocialLinks social-links-list" data-v-bb2aa2f0 data-v-7bc22406><!--[--><a class="VPSocialLink no-icon" href="https://github.com/Chevey339/kelivo" aria-label="github" target="_blank" rel="noopener" data-v-7bc22406 data-v-bd121fe5><span class="vpi-social-github"></span></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--[--><!--[--><!--[--><!--]--><!--[--><div class="tk-theme-enhance flx-align-center"><!--[--><i class="tk-icon" style="--icon-size:20px;--icon-color-hover:var(--tk-theme-color);"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1024 1024">
    <path
      fill="currentColor"
      d="m512 863.36 384-54.848v-638.72L525.568 222.72a96 96 0 0 1-27.136 0L128 169.792v638.72zM137.024 106.432l370.432 52.928a32 32 0 0 0 9.088 0l370.432-52.928A64 64 0 0 1 960 169.792v638.72a64 64 0 0 1-54.976 63.36l-388.48 55.488a32 32 0 0 1-9.088 0l-388.48-55.488A64 64 0 0 1 64 808.512v-638.72a64 64 0 0 1 73.024-63.36z"
    ></path>
    <path fill="currentColor" d="M480 192h64v704h-64z"></path>
  </svg></i><!--]--></div><!--teleport start--><!--teleport end--><!--]--><!--]--><!--]--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-6aa21345 data-v-e5dd9c1c><span class="container" data-v-e5dd9c1c><span class="top" data-v-e5dd9c1c></span><span class="middle" data-v-e5dd9c1c></span><span class="bottom" data-v-e5dd9c1c></span></span></button></div></div></div></div><div class="divider" data-v-6aa21345><div class="divider-line" data-v-6aa21345></div></div></div><!----></header><div class="VPLocalNav has-sidebar empty" data-v-9a104c51 data-v-a6f0e41e><div class="container" data-v-a6f0e41e><button class="menu" aria-expanded="false" aria-controls="VPSidebarNav" data-v-a6f0e41e><span class="vpi-align-left menu-icon" data-v-a6f0e41e></span><span class="menu-text" data-v-a6f0e41e>Menu</span></button><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-a6f0e41e data-v-8a42e2b4><button data-v-8a42e2b4>Return to top</button><!----></div></div></div><aside class="VPSidebar" data-v-9a104c51 data-v-319d5ca6><div class="curtain" data-v-319d5ca6></div><nav class="nav" id="VPSidebarNav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-319d5ca6><span class="visually-hidden" id="sidebar-aria-label" data-v-319d5ca6> Sidebar Navigation </span><!--[--><!--[--><!--v-if--><!--]--><!--]--><!--[--><div class="no-transition group" data-v-c40bc020><section class="VPSidebarItem level-0" data-v-c40bc020 data-v-b3fd67f8><div class="item" role="button" tabindex="0" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><h2 class="text" data-v-b3fd67f8>Getting Started</h2><!----></div><div class="items" data-v-b3fd67f8><!--[--><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/docs/getting-started/quick-start" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Quick Start</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/docs/getting-started/faq" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>FAQ</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/docs/getting-started/terminology" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Terminology</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-c40bc020><section class="VPSidebarItem level-0" data-v-c40bc020 data-v-b3fd67f8><div class="item" role="button" tabindex="0" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><h2 class="text" data-v-b3fd67f8>Assistant</h2><!----></div><div class="items" data-v-b3fd67f8><!--[--><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/docs/assistant/basics" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Basics</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/docs/assistant/prompts" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Prompts</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/docs/assistant/memory" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Memory</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/docs/assistant/custom-requests" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Custom Requests</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/docs/assistant/mcp" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>MCP</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-c40bc020><section class="VPSidebarItem level-0 has-active" data-v-c40bc020 data-v-b3fd67f8><div class="item" role="button" tabindex="0" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><h2 class="text" data-v-b3fd67f8>AI Providers</h2><!----></div><div class="items" data-v-b3fd67f8><!--[--><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/docs/providers/openai" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>OpenAI</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/docs/providers/anthropic" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Anthropic</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/docs/providers/google" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Google</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-c40bc020><section class="VPSidebarItem level-0" data-v-c40bc020 data-v-b3fd67f8><div class="item" role="button" tabindex="0" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><h2 class="text" data-v-b3fd67f8>Guides</h2><!----></div><div class="items" data-v-b3fd67f8><!--[--><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/docs/troubleshooting" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Troubleshooting</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b3fd67f8 data-v-b3fd67f8><div class="item" data-v-b3fd67f8><div class="indicator" data-v-b3fd67f8></div><a class="VPLink link link" href="/docs/best-practices" data-v-b3fd67f8><!--[--><p class="text" data-v-b3fd67f8>Best Practices</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><!--]--><!--[--><!--]--></nav></aside><div class="VPContent has-sidebar" id="VPContent" data-v-9a104c51 data-v-1428d186><div class="VPDoc has-sidebar has-aside" data-v-1428d186 data-v-39a288b8><!--[--><!--]--><div class="container" data-v-39a288b8><div class="aside" data-v-39a288b8><div class="aside-curtain" data-v-39a288b8></div><div class="aside-container" data-v-39a288b8><div class="aside-content" data-v-39a288b8><div class="VPDocAside" data-v-39a288b8 data-v-3f215769><!--[--><!--]--><!--[--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="VPDocAsideOutline" data-v-3f215769 data-v-a5bbad30><div class="content" data-v-a5bbad30><div class="outline-marker" data-v-a5bbad30></div><div aria-level="2" class="outline-title" id="doc-outline-aria-label" role="heading" data-v-a5bbad30>On this page</div><ul class="VPDocOutlineItem root" data-v-a5bbad30 data-v-b933a997><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-3f215769></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-39a288b8><div class="content-container" data-v-39a288b8><!--[--><!--[--><!--[--><!--[--><!--]--><!--[--><!--[--><!--]--><div class="tk-article-analyze flx-justify-between" aria-label="ÊñáÁ´†ÂàÜÊûê"><div class="tk-article-breadcrumb" role="navigation" aria-label="ÊñáÁ´†Èù¢ÂåÖÂ±ë"><div class="tk-breadcrumb" role="navigation" aria-label="Èù¢ÂåÖÂ±ë"><!--[--><span class="tk-breadcrumb__item"><span class="tk-breadcrumb__inner" role="link"><!--[--><a href="/" title="È¶ñÈ°µ" class="home hover-color" aria-label="È¶ñÈ°µ"><i class="tk-icon" style="--icon-color-hover:var(--tk-theme-color);" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1024 1024">
    <path
      fill="currentColor"
      d="M192 413.952V896h640V413.952L512 147.328zM139.52 374.4l352-293.312a32 32 0 0 1 40.96 0l352 293.312A32 32 0 0 1 896 398.976V928a32 32 0 0 1-32 32H160a32 32 0 0 1-32-32V398.976a32 32 0 0 1 11.52-24.576"
    ></path>
  </svg></i></a><!--]--></span><span class="tk-breadcrumb__separator" role="presentation">/</span></span><!--[--><span class="tk-breadcrumb__item"><span class="tk-breadcrumb__inner" role="link"><!--[--><span href title="docs" class="" aria-label="docs">docs</span><!--]--></span><span class="tk-breadcrumb__separator" role="presentation">/</span></span><span class="tk-breadcrumb__item"><span class="tk-breadcrumb__inner" role="link"><!--[--><span href title="providers" class="" aria-label="providers">providers</span><!--]--></span><span class="tk-breadcrumb__separator" role="presentation">/</span></span><!--]--><!--]--></div></div><div class="tk-article-analyze__wrapper flx-align-center"><div class="tk-article-info article" role="group" aria-label="ÊñáÁ´†‰ø°ÊÅØ"><!--[--><!--[--><!--v-if--><!--]--><!--[--><span class="tk-article-info__item" role="group" aria-label="ÂàõÂª∫Êó∂Èó¥"><i class="tk-icon tk-article-info__icon" style="--icon-color-hover:var(--tk-theme-color);" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1024 1024">
  <path
    fill="currentColor"
    d="M128 384v512h768V192H768v32a32 32 0 1 1-64 0v-32H320v32a32 32 0 0 1-64 0v-32H128v128h768v64zm192-256h384V96a32 32 0 1 1 64 0v32h160a32 32 0 0 1 32 32v768a32 32 0 0 1-32 32H96a32 32 0 0 1-32-32V160a32 32 0 0 1 32-32h160V96a32 32 0 0 1 64 0zm-32 384h64a32 32 0 0 1 0 64h-64a32 32 0 0 1 0-64m0 192h64a32 32 0 1 1 0 64h-64a32 32 0 1 1 0-64m192-192h64a32 32 0 0 1 0 64h-64a32 32 0 0 1 0-64m0 192h64a32 32 0 1 1 0 64h-64a32 32 0 1 1 0-64m192-192h64a32 32 0 1 1 0 64h-64a32 32 0 1 1 0-64m0 192h64a32 32 0 1 1 0 64h-64a32 32 0 1 1 0-64"
  ></path>
</svg></i><a title="ÂàõÂª∫Êó∂Èó¥" class="hover-color" aria-label="2025-09-02">2025-09-02</a></span><!--]--><!--[--><!--v-if--><!--]--><!--[--><!--v-if--><!--]--><!--[--><!--v-if--><!--]--><!--]--><!--[--><!--]--></div><div class="flx-center"><i class="tk-icon" style="--icon-color-hover:var(--tk-theme-color);" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1024 1024">
    <path
      fill="currentColor"
      d="m512 863.36 384-54.848v-638.72L525.568 222.72a96 96 0 0 1-27.136 0L128 169.792v638.72zM137.024 106.432l370.432 52.928a32 32 0 0 0 9.088 0l370.432-52.928A64 64 0 0 1 960 169.792v638.72a64 64 0 0 1-54.976 63.36l-388.48 55.488a32 32 0 0 1-9.088 0l-388.48-55.488A64 64 0 0 1 64 808.512v-638.72a64 64 0 0 1 73.024-63.36z"
    ></path>
    <path fill="currentColor" d="M480 192h64v704h-64z"></path>
  </svg></i><a title="ÊñáÁ´†Â≠óÊï∞" class="hover-color" aria-label="ÊñáÁ´†Â≠óÊï∞">2509</a></div><div class="flx-center"><i class="tk-icon" style="--icon-color-hover:var(--tk-theme-color);"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1024 1024">
    <path
      fill="currentColor"
      d="M512 896a384 384 0 1 0 0-768 384 384 0 0 0 0 768m0 64a448 448 0 1 1 0-896 448 448 0 0 1 0 896"
    ></path>
    <path fill="currentColor" d="M480 256a32 32 0 0 1 32 32v256a32 32 0 0 1-64 0V288a32 32 0 0 1 32-32"></path>
    <path fill="currentColor" d="M480 512h256q32 0 32 32t-32 32H480q-32 0-32-32t32-32"></path>
  </svg></i><a title="È¢ÑËÆ°ÈòÖËØªÊó∂Èïø" class="hover-color" aria-label="È¢ÑËÆ°ÈòÖËØªÊó∂Èïø">15.6m</a></div><!--v-if--></div></div><!--[--><!--]--><!--]--><!----><!----><!----><!--v-if--><!--v-if--><!--]--><!--]--><!--]--><main class="main" data-v-39a288b8><div style="position:relative;" class="vp-doc _docs_providers_openai" data-v-39a288b8><div><h1 id="openai-provider" tabindex="-1">OpenAI Provider <a class="header-anchor" href="#openai-provider" aria-label="Permalink to &quot;OpenAI Provider&quot;">‚Äã</a></h1><p>OpenAI offers industry-leading AI models including GPT-4, GPT-3.5, and the reasoning-focused o1 series.</p><h2 id="getting-started" tabindex="-1">Getting Started <a class="header-anchor" href="#getting-started" aria-label="Permalink to &quot;Getting Started&quot;">‚Äã</a></h2><h3 id="create-an-api-key" tabindex="-1">Create an API Key <a class="header-anchor" href="#create-an-api-key" aria-label="Permalink to &quot;Create an API Key&quot;">‚Äã</a></h3><ol><li>Visit <a href="https://platform.openai.com" target="_blank" rel="noreferrer">https://platform.openai.com</a></li><li>Sign up or log in</li><li>Navigate to <strong>API keys</strong> section</li><li>Click <strong>Create new secret key</strong></li><li><strong>Copy the key immediately</strong> (it won&#39;t be shown again)</li><li><strong>Name it</strong> for tracking (e.g., &quot;Kelivo Mobile&quot;)</li></ol><h3 id="add-to-kelivo" tabindex="-1">Add to Kelivo <a class="header-anchor" href="#add-to-kelivo" aria-label="Permalink to &quot;Add to Kelivo&quot;">‚Äã</a></h3><ol><li>Go to <strong>Settings ‚Üí Providers</strong></li><li>Tap <strong>Add Provider</strong> or <strong>+</strong></li><li>Fill in details: <ul><li><strong>Name</strong>: &quot;OpenAI&quot; or custom name</li><li><strong>Provider Type</strong>: OpenAI</li><li><strong>Base URL</strong>: <code>https://api.openai.com/v1</code> (default)</li><li><strong>API Key</strong>: Paste your key</li><li><strong>Default Model</strong>: gpt-4o (or your preferred model)</li></ul></li><li><strong>Save</strong></li></ol><h3 id="test-connection" tabindex="-1">Test Connection <a class="header-anchor" href="#test-connection" aria-label="Permalink to &quot;Test Connection&quot;">‚Äã</a></h3><p>Send a test message to verify:</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>User: Hello!</span></span>
<span class="line"><span>AI: Hello! How can I help you today?</span></span></code></pre></div><p>If it works, you&#39;re all set!</p><h2 id="available-models" tabindex="-1">Available Models <a class="header-anchor" href="#available-models" aria-label="Permalink to &quot;Available Models&quot;">‚Äã</a></h2><h3 id="gpt-4-series-most-capable" tabindex="-1">GPT-4 Series (Most Capable) <a class="header-anchor" href="#gpt-4-series-most-capable" aria-label="Permalink to &quot;GPT-4 Series (Most Capable)&quot;">‚Äã</a></h3><p><strong>gpt-4o</strong> (Recommended)</p><ul><li><strong>Best for</strong>: General use, vision, most tasks</li><li><strong>Context</strong>: 128K tokens</li><li><strong>Features</strong>: Text, vision, function calling, JSON mode</li><li><strong>Speed</strong>: Fast</li><li><strong>Cost</strong>: Moderate</li><li><strong>Use when</strong>: You need high quality and speed</li></ul><p><strong>gpt-4-turbo</strong></p><ul><li><strong>Best for</strong>: Complex tasks, long documents</li><li><strong>Context</strong>: 128K tokens</li><li><strong>Features</strong>: Text, vision, function calling</li><li><strong>Speed</strong>: Moderate</li><li><strong>Cost</strong>: Higher</li><li><strong>Use when</strong>: You need maximum capability</li></ul><p><strong>gpt-4</strong> (Original)</p><ul><li><strong>Best for</strong>: Consistency, proven reliability</li><li><strong>Context</strong>: 8K tokens</li><li><strong>Features</strong>: Text only</li><li><strong>Speed</strong>: Slower</li><li><strong>Cost</strong>: High</li><li><strong>Use when</strong>: Legacy applications</li></ul><h3 id="gpt-3-5-series-fast-economical" tabindex="-1">GPT-3.5 Series (Fast &amp; Economical) <a class="header-anchor" href="#gpt-3-5-series-fast-economical" aria-label="Permalink to &quot;GPT-3.5 Series (Fast &amp; Economical)&quot;">‚Äã</a></h3><p><strong>gpt-3.5-turbo</strong></p><ul><li><strong>Best for</strong>: Quick tasks, high volume, cost-sensitive use</li><li><strong>Context</strong>: 16K tokens</li><li><strong>Features</strong>: Text, function calling</li><li><strong>Speed</strong>: Very fast</li><li><strong>Cost</strong>: Low</li><li><strong>Use when</strong>: Simple tasks, speed matters</li></ul><h3 id="o1-series-reasoning-models" tabindex="-1">o1 Series (Reasoning Models) <a class="header-anchor" href="#o1-series-reasoning-models" aria-label="Permalink to &quot;o1 Series (Reasoning Models)&quot;">‚Äã</a></h3><p><strong>o1-preview</strong></p><ul><li><strong>Best for</strong>: Complex reasoning, math, code, science</li><li><strong>Context</strong>: 128K tokens</li><li><strong>Features</strong>: Deep reasoning, no streaming</li><li><strong>Speed</strong>: Slower (thinks before responding)</li><li><strong>Cost</strong>: Higher</li><li><strong>Use when</strong>: Problems require step-by-step thinking</li></ul><p><strong>o1-mini</strong></p><ul><li><strong>Best for</strong>: Coding, STEM problems, cost-conscious reasoning</li><li><strong>Context</strong>: 128K tokens</li><li><strong>Features</strong>: Faster reasoning, more affordable</li><li><strong>Speed</strong>: Moderate</li><li><strong>Cost</strong>: Lower than o1-preview</li><li><strong>Use when</strong>: Coding or math on a budget</li></ul><h3 id="model-comparison" tabindex="-1">Model Comparison <a class="header-anchor" href="#model-comparison" aria-label="Permalink to &quot;Model Comparison&quot;">‚Äã</a></h3><table tabindex="0"><thead><tr><th>Model</th><th>Speed</th><th>Quality</th><th>Cost</th><th>Vision</th><th>Best Use Case</th></tr></thead><tbody><tr><td>gpt-4o</td><td>‚ö°‚ö°‚ö°</td><td>‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê</td><td>üí∞üí∞</td><td>‚úÖ</td><td>General purpose</td></tr><tr><td>gpt-4-turbo</td><td>‚ö°‚ö°</td><td>‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê</td><td>üí∞üí∞üí∞</td><td>‚úÖ</td><td>Long documents</td></tr><tr><td>gpt-3.5-turbo</td><td>‚ö°‚ö°‚ö°‚ö°</td><td>‚≠ê‚≠ê‚≠ê</td><td>üí∞</td><td>‚ùå</td><td>Simple tasks</td></tr><tr><td>o1-preview</td><td>‚ö°</td><td>‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê</td><td>üí∞üí∞üí∞üí∞</td><td>‚ùå</td><td>Complex reasoning</td></tr><tr><td>o1-mini</td><td>‚ö°‚ö°</td><td>‚≠ê‚≠ê‚≠ê‚≠ê</td><td>üí∞üí∞</td><td>‚ùå</td><td>Coding, STEM</td></tr></tbody></table><h2 id="features-capabilities" tabindex="-1">Features &amp; Capabilities <a class="header-anchor" href="#features-capabilities" aria-label="Permalink to &quot;Features &amp; Capabilities&quot;">‚Äã</a></h2><h3 id="vision-multimodal" tabindex="-1">Vision (Multimodal) <a class="header-anchor" href="#vision-multimodal" aria-label="Permalink to &quot;Vision (Multimodal)&quot;">‚Äã</a></h3><p><strong>Supported models</strong>: gpt-4o, gpt-4-turbo, gpt-4-vision-preview</p><p><strong>Use cases</strong>:</p><ul><li>Describe images</li><li>Extract text from screenshots</li><li>Analyze charts and diagrams</li><li>Answer questions about photos</li><li>Generate image captions</li></ul><p><strong>Example</strong>:</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>User: [attaches screenshot] What&#39;s in this error message?</span></span>
<span class="line"><span>AI: The error shows a &quot;Module not found&quot; exception...</span></span></code></pre></div><p><strong>Tips</strong>:</p><ul><li>High-resolution images cost more tokens</li><li>Consider resizing large images</li><li>Works with multiple images in one message</li></ul><h3 id="function-calling" tabindex="-1">Function Calling <a class="header-anchor" href="#function-calling" aria-label="Permalink to &quot;Function Calling&quot;">‚Äã</a></h3><p><strong>Supported models</strong>: All except o1 series (limited support)</p><p><strong>Use cases</strong>:</p><ul><li>Structured data extraction</li><li>API integrations</li><li>Tool usage (web search, calculations)</li><li>Database queries</li></ul><p><strong>Example</strong>:</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>User: What&#39;s the weather in Tokyo?</span></span>
<span class="line"><span>AI: [calls get_weather function with location=&quot;Tokyo&quot;]</span></span>
<span class="line"><span>AI: It&#39;s currently 22¬∞C and partly cloudy in Tokyo.</span></span></code></pre></div><h3 id="json-mode" tabindex="-1">JSON Mode <a class="header-anchor" href="#json-mode" aria-label="Permalink to &quot;JSON Mode&quot;">‚Äã</a></h3><p><strong>Supported models</strong>: gpt-4o, gpt-4-turbo, gpt-3.5-turbo</p><p><strong>Use cases</strong>:</p><ul><li>Structured output</li><li>Data extraction</li><li>API responses</li></ul><p><strong>Enable</strong>: Add to request (via custom prompts or provider settings)</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>{</span></span>
<span class="line"><span>  &quot;response_format&quot;: { &quot;type&quot;: &quot;json_object&quot; }</span></span>
<span class="line"><span>}</span></span></code></pre></div><p><strong>Example</strong>:</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>User: Extract: &quot;John works at Google as a developer&quot;</span></span>
<span class="line"><span>AI: {&quot;name&quot;: &quot;John&quot;, &quot;company&quot;: &quot;Google&quot;, &quot;role&quot;: &quot;developer&quot;}</span></span></code></pre></div><h3 id="streaming" tabindex="-1">Streaming <a class="header-anchor" href="#streaming" aria-label="Permalink to &quot;Streaming&quot;">‚Äã</a></h3><p><strong>All models support streaming</strong> for real-time responses.</p><p><strong>Benefits</strong>:</p><ul><li>Faster perceived response time</li><li>Can stop generation mid-response</li><li>Better user experience</li></ul><p>Kelivo enables streaming by default.</p><h2 id="configuration-tips" tabindex="-1">Configuration Tips <a class="header-anchor" href="#configuration-tips" aria-label="Permalink to &quot;Configuration Tips&quot;">‚Äã</a></h2><h3 id="temperature-settings" tabindex="-1">Temperature Settings <a class="header-anchor" href="#temperature-settings" aria-label="Permalink to &quot;Temperature Settings&quot;">‚Äã</a></h3><p><strong>For different models</strong>:</p><ul><li><strong>GPT-4o, GPT-4</strong>: 0.7 (default, balanced)</li><li><strong>GPT-3.5</strong>: 0.5-0.7 (more focused)</li><li><strong>o1 series</strong>: Fixed internally (don&#39;t adjust)</li></ul><p><strong>For different tasks</strong>:</p><ul><li><strong>Code</strong>: 0.2-0.3 (deterministic)</li><li><strong>Writing</strong>: 0.8-1.0 (creative)</li><li><strong>Analysis</strong>: 0.3-0.5 (focused)</li><li><strong>Brainstorming</strong>: 1.0-1.2 (diverse)</li></ul><h3 id="max-tokens" tabindex="-1">Max Tokens <a class="header-anchor" href="#max-tokens" aria-label="Permalink to &quot;Max Tokens&quot;">‚Äã</a></h3><p>Control response length:</p><ul><li><strong>Short answers</strong>: 256-512 tokens</li><li><strong>Medium</strong>: 1024-2048 tokens</li><li><strong>Long form</strong>: 4096+ tokens</li></ul><p><strong>Tip</strong>: Leave headroom in context window for conversation history.</p><h3 id="system-prompts" tabindex="-1">System Prompts <a class="header-anchor" href="#system-prompts" aria-label="Permalink to &quot;System Prompts&quot;">‚Äã</a></h3><p>OpenAI models respond well to:</p><ul><li>Clear role definitions</li><li>Numbered instructions</li><li>Examples (few-shot)</li><li>Explicit formatting requests</li></ul><p><strong>Example</strong>:</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>You are a senior Python developer. Provide clean, well-documented code with type hints. Always consider edge cases and error handling.</span></span></code></pre></div><h2 id="pricing-rate-limits" tabindex="-1">Pricing &amp; Rate Limits <a class="header-anchor" href="#pricing-rate-limits" aria-label="Permalink to &quot;Pricing &amp; Rate Limits&quot;">‚Äã</a></h2><h3 id="pricing-as-of-2025" tabindex="-1">Pricing (as of 2025) <a class="header-anchor" href="#pricing-as-of-2025" aria-label="Permalink to &quot;Pricing (as of 2025)&quot;">‚Äã</a></h3><p><strong>Input/Output tokens</strong>:</p><ul><li><strong>gpt-4o</strong>: $2.50/$10.00 per 1M tokens</li><li><strong>gpt-4-turbo</strong>: $10.00/$30.00 per 1M tokens</li><li><strong>gpt-3.5-turbo</strong>: $0.50/$1.50 per 1M tokens</li><li><strong>o1-preview</strong>: $15.00/$60.00 per 1M tokens</li><li><strong>o1-mini</strong>: $3.00/$12.00 per 1M tokens</li></ul><p><strong>Note</strong>: Prices may change. Check <a href="https://openai.com/pricing" target="_blank" rel="noreferrer">https://openai.com/pricing</a> for current rates.</p><h3 id="rate-limits" tabindex="-1">Rate Limits <a class="header-anchor" href="#rate-limits" aria-label="Permalink to &quot;Rate Limits&quot;">‚Äã</a></h3><p><strong>Free tier</strong>:</p><ul><li>3 requests per minute (RPM)</li><li>40,000 tokens per minute (TPM)</li><li>200 requests per day (RPD)</li></ul><p><strong>Paid tier 1</strong>:</p><ul><li>3,500 RPM (GPT-4)</li><li>90,000 TPM</li><li>Higher limits after usage</li></ul><p><strong>Paid tier 2+</strong>:</p><ul><li>5,000+ RPM</li><li>450,000+ TPM</li><li>Scale with usage</li></ul><p><strong>Tip</strong>: Upgrade to paid tier for better limits. Monitor usage in OpenAI dashboard.</p><h2 id="troubleshooting" tabindex="-1">Troubleshooting <a class="header-anchor" href="#troubleshooting" aria-label="Permalink to &quot;Troubleshooting&quot;">‚Äã</a></h2><h3 id="rate-limit-errors-429" tabindex="-1">Rate Limit Errors (429) <a class="header-anchor" href="#rate-limit-errors-429" aria-label="Permalink to &quot;Rate Limit Errors (429)&quot;">‚Äã</a></h3><p><strong>Error</strong>: &quot;Rate limit exceeded&quot;</p><p><strong>Solutions</strong>:</p><ol><li><strong>Wait</strong>: Limits reset per minute</li><li><strong>Upgrade tier</strong>: Use more, get higher limits</li><li><strong>Switch model</strong>: Use GPT-3.5 if GPT-4 is limited</li><li><strong>Reduce frequency</strong>: Add delays between requests</li></ol><h3 id="invalid-api-key-401" tabindex="-1">Invalid API Key (401) <a class="header-anchor" href="#invalid-api-key-401" aria-label="Permalink to &quot;Invalid API Key (401)&quot;">‚Äã</a></h3><p><strong>Error</strong>: &quot;Incorrect API key provided&quot;</p><p><strong>Solutions</strong>:</p><ol><li><strong>Verify key</strong>: Copy entire key, no extra spaces</li><li><strong>Check status</strong>: Ensure key hasn&#39;t been revoked</li><li><strong>Regenerate</strong>: Create new key if lost</li><li><strong>Organization</strong>: Verify org access if applicable</li></ol><h3 id="model-not-found-404" tabindex="-1">Model Not Found (404) <a class="header-anchor" href="#model-not-found-404" aria-label="Permalink to &quot;Model Not Found (404)&quot;">‚Äã</a></h3><p><strong>Error</strong>: &quot;The model &#39;xyz&#39; does not exist&quot;</p><p><strong>Solutions</strong>:</p><ol><li><strong>Check name</strong>: Use exact model names (e.g., &quot;gpt-4o&quot; not &quot;gpt4o&quot;)</li><li><strong>Access</strong>: Verify your account has access (o1 requires waitlist approval)</li><li><strong>Region</strong>: Some models limited to certain regions</li></ol><h3 id="context-length-exceeded" tabindex="-1">Context Length Exceeded <a class="header-anchor" href="#context-length-exceeded" aria-label="Permalink to &quot;Context Length Exceeded&quot;">‚Äã</a></h3><p><strong>Error</strong>: &quot;This model&#39;s maximum context length is...&quot;</p><p><strong>Solutions</strong>:</p><ol><li><strong>Shorten input</strong>: Reduce conversation history</li><li><strong>Use larger model</strong>: GPT-4-turbo has 128K context</li><li><strong>Summarize</strong>: Condense old messages</li><li><strong>Clear history</strong>: Start fresh conversation</li></ol><h3 id="slow-responses" tabindex="-1">Slow Responses <a class="header-anchor" href="#slow-responses" aria-label="Permalink to &quot;Slow Responses&quot;">‚Äã</a></h3><p><strong>Solutions</strong>:</p><ol><li><strong>Use faster model</strong>: GPT-3.5 or gpt-4o</li><li><strong>Streaming</strong>: Should be enabled by default</li><li><strong>Reduce load</strong>: Shorter prompts, less context</li><li><strong>Check status</strong>: <a href="https://status.openai.com" target="_blank" rel="noreferrer">https://status.openai.com</a></li></ol><h2 id="advanced-features" tabindex="-1">Advanced Features <a class="header-anchor" href="#advanced-features" aria-label="Permalink to &quot;Advanced Features&quot;">‚Äã</a></h2><h3 id="organization-id" tabindex="-1">Organization ID <a class="header-anchor" href="#organization-id" aria-label="Permalink to &quot;Organization ID&quot;">‚Äã</a></h3><p>For teams with multiple projects:</p><ol><li>Find your org ID: <a href="https://platform.openai.com/account/organization" target="_blank" rel="noreferrer">https://platform.openai.com/account/organization</a></li><li>Add custom header in Kelivo:<div class="language-json vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">json</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">{</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  &quot;OpenAI-Organization&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;org-xxxxxxxxxxxxx&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">}</span></span></code></pre></div></li></ol><h3 id="azure-openai" tabindex="-1">Azure OpenAI <a class="header-anchor" href="#azure-openai" aria-label="Permalink to &quot;Azure OpenAI&quot;">‚Äã</a></h3><p>Use OpenAI models via Azure:</p><p><strong>Base URL</strong>:</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>https://YOUR-RESOURCE-NAME.openai.azure.com</span></span></code></pre></div><p><strong>API Key</strong>: Azure OpenAI key (not OpenAI key)</p><p><strong>Model Deployment</strong>: Use your deployment name</p><p>See <a href="/docs/assistant/custom-requests">Custom Requests</a> for details.</p><h3 id="openrouter-access-200-models-via-openai-api" tabindex="-1">OpenRouter - Access 200+ Models via OpenAI API <a class="header-anchor" href="#openrouter-access-200-models-via-openai-api" aria-label="Permalink to &quot;OpenRouter - Access 200+ Models via OpenAI API&quot;">‚Äã</a></h3><p><strong>OpenRouter</strong> is an OpenAI-compatible gateway that aggregates models from multiple providers into a single API. It offers significantly more model choices than OpenAI alone, with unified pricing and a single API key.</p><h4 id="why-use-openrouter" tabindex="-1">Why Use OpenRouter? <a class="header-anchor" href="#why-use-openrouter" aria-label="Permalink to &quot;Why Use OpenRouter?&quot;">‚Äã</a></h4><p><strong>Access to 200+ Models</strong>:</p><ul><li>OpenAI (GPT-4, GPT-3.5)</li><li>Anthropic (Claude 3.5, Claude 3)</li><li>Google (Gemini Pro, Gemini Flash)</li><li>Meta (Llama 3.1, Llama 3.2)</li><li>Mistral (Mistral Large, Mistral Medium)</li><li>Cohere (Command R+)</li><li>Open-source models (Mixtral, Yi, Qwen)</li><li>And many more</li></ul><p><strong>Benefits</strong>:</p><ul><li><strong>Single API key</strong> for all providers</li><li><strong>Unified pricing</strong> across models</li><li><strong>Lower costs</strong> for many models</li><li><strong>No rate limits</strong> on most models</li><li><strong>Fallback support</strong> (auto-switch if model is down)</li><li><strong>Model routing</strong> (automatically choose best model)</li><li><strong>Usage tracking</strong> in one dashboard</li></ul><h4 id="getting-started-with-openrouter" tabindex="-1">Getting Started with OpenRouter <a class="header-anchor" href="#getting-started-with-openrouter" aria-label="Permalink to &quot;Getting Started with OpenRouter&quot;">‚Äã</a></h4><p><strong>1. Create an API Key</strong></p><ol><li>Visit <a href="https://openrouter.ai" target="_blank" rel="noreferrer">https://openrouter.ai</a></li><li>Sign up or log in</li><li>Go to <strong>Keys</strong> section</li><li>Click <strong>Create Key</strong></li><li><strong>Name your key</strong> (e.g., &quot;Kelivo&quot;)</li><li><strong>Copy the key</strong> (starts with <code>sk-or-v1-</code>)</li><li><strong>Add credits</strong> (minimum $5, pay-as-you-go)</li></ol><p><strong>2. Add to Kelivo</strong></p><ol><li>Go to <strong>Settings ‚Üí Providers</strong></li><li>Tap <strong>Add Provider</strong> or <strong>+</strong></li><li>Fill in details: <ul><li><strong>Name</strong>: &quot;OpenRouter&quot; or custom name</li><li><strong>Provider Type</strong>: OpenAI (OpenRouter is OpenAI-compatible)</li><li><strong>Base URL</strong>: <code>https://openrouter.ai/api/v1</code></li><li><strong>API Key</strong>: Paste your OpenRouter key (sk-or-v1-...)</li><li><strong>Default Model</strong>: See model recommendations below</li></ul></li><li><strong>Save</strong></li></ol><p><strong>3. Test Connection</strong></p><p>Send a test message to verify:</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>User: Hello!</span></span>
<span class="line"><span>AI: Hello! How can I help you today?</span></span></code></pre></div><h4 id="recommended-models-on-openrouter" tabindex="-1">Recommended Models on OpenRouter <a class="header-anchor" href="#recommended-models-on-openrouter" aria-label="Permalink to &quot;Recommended Models on OpenRouter&quot;">‚Äã</a></h4><p><strong>Best Value Models</strong>:</p><p><strong>anthropic/claude-3.5-sonnet</strong> (Highly Recommended)</p><ul><li><strong>Best for</strong>: General purpose, excellent quality</li><li><strong>Context</strong>: 200K tokens</li><li><strong>Cost</strong>: ~$3/$15 per 1M tokens (input/output)</li><li><strong>Features</strong>: Vision, function calling, artifacts</li><li><strong>Why</strong>: Best quality-to-price ratio, beats GPT-4o</li></ul><p><strong>google/gemini-pro-1.5</strong> (Free Tier Available)</p><ul><li><strong>Best for</strong>: Long context, cost-conscious use</li><li><strong>Context</strong>: 2M tokens (!!)</li><li><strong>Cost</strong>: FREE up to limits, then $0.35/$1.05 per 1M tokens</li><li><strong>Features</strong>: Vision, massive context window</li><li><strong>Why</strong>: Incredible value, huge context</li></ul><p><strong>meta-llama/llama-3.1-70b-instruct</strong> (Open Source)</p><ul><li><strong>Best for</strong>: Privacy-conscious, open source preference</li><li><strong>Context</strong>: 128K tokens</li><li><strong>Cost</strong>: ~$0.50/$0.75 per 1M tokens</li><li><strong>Features</strong>: Strong reasoning, fast</li><li><strong>Why</strong>: Excellent open-source option</li></ul><p><strong>openai/gpt-4o</strong> (Latest OpenAI)</p><ul><li><strong>Best for</strong>: Tasks requiring latest GPT-4 capabilities</li><li><strong>Context</strong>: 128K tokens</li><li><strong>Cost</strong>: $2.50/$10 per 1M tokens (same as OpenAI)</li><li><strong>Features</strong>: Vision, function calling, fast</li><li><strong>Why</strong>: Latest OpenAI model, same price</li></ul><p><strong>Budget Options</strong>:</p><p><strong>mistralai/mistral-7b-instruct</strong> (~$0.07/$0.07 per 1M tokens)</p><ul><li>Fast, cheap, good for simple tasks</li></ul><p><strong>google/gemini-flash-1.5</strong> (~$0.075/$0.30 per 1M tokens)</p><ul><li>Very fast, excellent for high-volume simple tasks</li></ul><p><strong>meta-llama/llama-3.2-3b-instruct</strong> (~$0.06/$0.06 per 1M tokens)</p><ul><li>Extremely cheap, good for basic tasks</li></ul><p><strong>Premium Options</strong>:</p><p><strong>anthropic/claude-3-opus</strong> (~$15/$75 per 1M tokens)</p><ul><li>Most capable Claude model, best reasoning</li></ul><p><strong>openai/o1-preview</strong> (~$15/$60 per 1M tokens)</p><ul><li>Advanced reasoning, complex problem solving</li></ul><p><strong>google/gemini-pro-1.5-exp</strong> (~$0.35/$1.05 per 1M tokens)</p><ul><li>Experimental Gemini with latest features</li></ul><h4 id="model-categories" tabindex="-1">Model Categories <a class="header-anchor" href="#model-categories" aria-label="Permalink to &quot;Model Categories&quot;">‚Äã</a></h4><p><strong>By Use Case</strong>:</p><p><strong>General Purpose</strong>:</p><ul><li>anthropic/claude-3.5-sonnet (best overall)</li><li>openai/gpt-4o (latest GPT-4)</li><li>google/gemini-pro-1.5 (best value)</li></ul><p><strong>Coding</strong>:</p><ul><li>anthropic/claude-3.5-sonnet (excellent at code)</li><li>meta-llama/llama-3.1-405b-instruct (open source, powerful)</li><li>openai/gpt-4o (strong coding)</li></ul><p><strong>Long Context</strong>:</p><ul><li>google/gemini-pro-1.5 (2M tokens!)</li><li>anthropic/claude-3.5-sonnet (200K tokens)</li><li>openai/gpt-4o (128K tokens)</li></ul><p><strong>Fast &amp; Cheap</strong>:</p><ul><li>google/gemini-flash-1.5 (very fast)</li><li>mistralai/mistral-7b-instruct (cheap)</li><li>meta-llama/llama-3.2-3b-instruct (cheapest)</li></ul><p><strong>Reasoning &amp; Analysis</strong>:</p><ul><li>openai/o1-preview (advanced reasoning)</li><li>anthropic/claude-3-opus (deep thinking)</li><li>perplexity/llama-3.1-sonar-large (web search integrated)</li></ul><p><strong>Vision</strong>:</p><ul><li>anthropic/claude-3.5-sonnet (excellent vision)</li><li>openai/gpt-4o (strong vision)</li><li>google/gemini-pro-1.5 (good vision)</li></ul><h4 id="pricing-comparison" tabindex="-1">Pricing Comparison <a class="header-anchor" href="#pricing-comparison" aria-label="Permalink to &quot;Pricing Comparison&quot;">‚Äã</a></h4><p>OpenRouter often offers <strong>better pricing</strong> than direct providers:</p><table tabindex="0"><thead><tr><th>Model</th><th>OpenRouter</th><th>Direct Provider</th><th>Savings</th></tr></thead><tbody><tr><td>Claude 3.5 Sonnet</td><td>$3/$15 per 1M</td><td>$3/$15 per 1M</td><td>Same</td></tr><tr><td>GPT-4o</td><td>$2.50/$10 per 1M</td><td>$2.50/$10 per 1M</td><td>Same</td></tr><tr><td>Gemini Pro 1.5</td><td>Free tier!</td><td>Paid only</td><td>Better</td></tr><tr><td>Llama 3.1 70B</td><td>$0.50/$0.75 per 1M</td><td>Self-host</td><td>Much easier</td></tr><tr><td>Mistral 7B</td><td>$0.07/$0.07 per 1M</td><td>‚Ç¨0.20+</td><td>~65% savings</td></tr></tbody></table><p><strong>Pay-as-you-go</strong>: No subscriptions, only pay for what you use.</p><h4 id="openrouter-specific-features" tabindex="-1">OpenRouter-Specific Features <a class="header-anchor" href="#openrouter-specific-features" aria-label="Permalink to &quot;OpenRouter-Specific Features&quot;">‚Äã</a></h4><p><strong>Model Fallbacks</strong>: Add to custom headers:</p><div class="language-json vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">json</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">{</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  &quot;X-Title&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Kelivo Chat&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  &quot;HTTP-Referer&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;https://kelivo.app&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  &quot;X-Model-Fallbacks&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: [</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;anthropic/claude-3.5-sonnet&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;openai/gpt-4o&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">}</span></span></code></pre></div><p>If primary model fails, automatically uses fallback.</p><p><strong>Model Routing</strong> (Auto-select): Use <code>openrouter/auto</code> as model name to let OpenRouter choose the best model for your prompt.</p><p><strong>Provider Preferences</strong>: Route models through specific providers for better rates or availability.</p><p><strong>Usage Tracking</strong>: Monitor all model usage in one dashboard at <a href="https://openrouter.ai/activity" target="_blank" rel="noreferrer">https://openrouter.ai/activity</a></p><h4 id="configuration-tips-1" tabindex="-1">Configuration Tips <a class="header-anchor" href="#configuration-tips-1" aria-label="Permalink to &quot;Configuration Tips&quot;">‚Äã</a></h4><p><strong>Custom Headers</strong> (Optional but Recommended):</p><p>Add these in Kelivo provider settings:</p><div class="language-json vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">json</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">{</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  &quot;HTTP-Referer&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;https://kelivo.app&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  &quot;X-Title&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Kelivo Mobile&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">}</span></span></code></pre></div><p><strong>Benefits</strong>:</p><ul><li>Helps OpenRouter improve service</li><li>May unlock better rates in future</li><li>Enables better analytics</li></ul><p><strong>Model Selection</strong>:</p><p>Format: <code>provider/model-name</code></p><ul><li>‚úÖ Correct: <code>anthropic/claude-3.5-sonnet</code></li><li>‚úÖ Correct: <code>openai/gpt-4o</code></li><li>‚úÖ Correct: <code>google/gemini-pro-1.5</code></li><li>‚ùå Wrong: <code>claude-3.5-sonnet</code> (missing provider)</li></ul><p><strong>Find Models</strong>: Browse all available models at <a href="https://openrouter.ai/models" target="_blank" rel="noreferrer">https://openrouter.ai/models</a></p><h4 id="troubleshooting-1" tabindex="-1">Troubleshooting <a class="header-anchor" href="#troubleshooting-1" aria-label="Permalink to &quot;Troubleshooting&quot;">‚Äã</a></h4><p><strong>Invalid Model Name</strong>:</p><ul><li>Use full format: <code>provider/model-name</code></li><li>Check model list: <a href="https://openrouter.ai/models" target="_blank" rel="noreferrer">https://openrouter.ai/models</a></li><li>Some models require special access</li></ul><p><strong>Insufficient Credits</strong>:</p><ul><li>Add more credits at <a href="https://openrouter.ai/credits" target="_blank" rel="noreferrer">https://openrouter.ai/credits</a></li><li>Minimum $5 top-up</li><li>Credits never expire</li></ul><p><strong>Rate Limits</strong>:</p><ul><li>Most models have no rate limits</li><li>Some premium models may have provider-specific limits</li><li>Check model page for details</li></ul><p><strong>Model Unavailable</strong>:</p><ul><li>Provider may be temporarily down</li><li>Use model fallbacks feature</li><li>Try alternative model</li></ul><h4 id="cost-optimization" tabindex="-1">Cost Optimization <a class="header-anchor" href="#cost-optimization" aria-label="Permalink to &quot;Cost Optimization&quot;">‚Äã</a></h4><p><strong>Smart Model Selection</strong>:</p><ol><li><strong>Start with free tier</strong>: google/gemini-pro-1.5 for most tasks</li><li><strong>Use cheap models</strong>: mistralai/mistral-7b-instruct for simple tasks</li><li><strong>Reserve premium</strong>: anthropic/claude-3.5-sonnet for complex work</li><li><strong>Avoid expensive</strong>: Only use o1-preview or claude-3-opus when needed</li></ol><p><strong>Monitor Usage</strong>:</p><ul><li>Check dashboard: <a href="https://openrouter.ai/activity" target="_blank" rel="noreferrer">https://openrouter.ai/activity</a></li><li>Set up spending alerts</li><li>Review per-model costs</li></ul><p><strong>Context Management</strong>:</p><ul><li>Keep conversations focused</li><li>Clear history regularly</li><li>Use smaller models for follow-ups</li></ul><h4 id="resources" tabindex="-1">Resources <a class="header-anchor" href="#resources" aria-label="Permalink to &quot;Resources&quot;">‚Äã</a></h4><p><strong>Official Links</strong>:</p><ul><li>OpenRouter Homepage: <a href="https://openrouter.ai" target="_blank" rel="noreferrer">https://openrouter.ai</a></li><li>Model List: <a href="https://openrouter.ai/models" target="_blank" rel="noreferrer">https://openrouter.ai/models</a></li><li>Pricing: <a href="https://openrouter.ai/docs#pricing" target="_blank" rel="noreferrer">https://openrouter.ai/docs#pricing</a></li><li>API Docs: <a href="https://openrouter.ai/docs" target="_blank" rel="noreferrer">https://openrouter.ai/docs</a></li><li>Activity Dashboard: <a href="https://openrouter.ai/activity" target="_blank" rel="noreferrer">https://openrouter.ai/activity</a></li></ul><p><strong>Community</strong>:</p><ul><li>Discord: <a href="https://discord.gg/openrouter" target="_blank" rel="noreferrer">https://discord.gg/openrouter</a></li><li>GitHub: <a href="https://github.com/OpenRouterTeam" target="_blank" rel="noreferrer">https://github.com/OpenRouterTeam</a></li></ul><h3 id="other-openai-compatible-providers" tabindex="-1">Other OpenAI-Compatible Providers <a class="header-anchor" href="#other-openai-compatible-providers" aria-label="Permalink to &quot;Other OpenAI-Compatible Providers&quot;">‚Äã</a></h3><p><strong>Examples</strong>:</p><ul><li><strong>Together AI</strong>: Open-source models, fast inference</li><li><strong>Groq</strong>: Ultra-fast inference for open models</li><li><strong>Anyscale</strong>: Llama and Mistral models</li><li><strong>Fireworks AI</strong>: Fast open-source models</li></ul><p><strong>Setup</strong>: Change base URL, use their API key</p><h2 id="best-practices" tabindex="-1">Best Practices <a class="header-anchor" href="#best-practices" aria-label="Permalink to &quot;Best Practices&quot;">‚Äã</a></h2><h3 id="model-selection" tabindex="-1">Model Selection <a class="header-anchor" href="#model-selection" aria-label="Permalink to &quot;Model Selection&quot;">‚Äã</a></h3><ul><li><strong>Default</strong>: gpt-4o for most users</li><li><strong>Budget</strong>: gpt-3.5-turbo for high volume</li><li><strong>Complex tasks</strong>: gpt-4-turbo or o1-preview</li><li><strong>Code</strong>: o1-mini or gpt-4o</li><li><strong>Speed</strong>: gpt-3.5-turbo or gpt-4o</li></ul><h3 id="cost-optimization-1" tabindex="-1">Cost Optimization <a class="header-anchor" href="#cost-optimization-1" aria-label="Permalink to &quot;Cost Optimization&quot;">‚Äã</a></h3><ol><li><strong>Right-size model</strong>: Don&#39;t use GPT-4 for simple tasks</li><li><strong>Shorten prompts</strong>: Remove unnecessary context</li><li><strong>Manage history</strong>: Limit conversation length</li><li><strong>Use caching</strong>: Reuse system prompts (provider-level)</li><li><strong>Monitor usage</strong>: Check OpenAI dashboard regularly</li></ol><h3 id="security" tabindex="-1">Security <a class="header-anchor" href="#security" aria-label="Permalink to &quot;Security&quot;">‚Äã</a></h3><ol><li><strong>Protect API keys</strong>: Never share or commit to repos</li><li><strong>Rotate keys</strong>: Periodic rotation policy</li><li><strong>Use separate keys</strong>: Different keys for dev/prod</li><li><strong>Monitor usage</strong>: Watch for unusual activity</li><li><strong>Set spending limits</strong>: In OpenAI dashboard</li></ol><h3 id="performance" tabindex="-1">Performance <a class="header-anchor" href="#performance" aria-label="Permalink to &quot;Performance&quot;">‚Äã</a></h3><ol><li><strong>Enable streaming</strong>: For better UX</li><li><strong>Parallel requests</strong>: For independent tasks</li><li><strong>Appropriate timeouts</strong>: 60s for GPT-4, 30s for GPT-3.5</li><li><strong>Retry logic</strong>: Handle transient failures</li></ol><h2 id="resources-1" tabindex="-1">Resources <a class="header-anchor" href="#resources-1" aria-label="Permalink to &quot;Resources&quot;">‚Äã</a></h2><h3 id="official-documentation" tabindex="-1">Official Documentation <a class="header-anchor" href="#official-documentation" aria-label="Permalink to &quot;Official Documentation&quot;">‚Äã</a></h3><ul><li>OpenAI Platform: <a href="https://platform.openai.com" target="_blank" rel="noreferrer">https://platform.openai.com</a></li><li>API Reference: <a href="https://platform.openai.com/docs/api-reference" target="_blank" rel="noreferrer">https://platform.openai.com/docs/api-reference</a></li><li>Pricing: <a href="https://openai.com/pricing" target="_blank" rel="noreferrer">https://openai.com/pricing</a></li><li>Status: <a href="https://status.openai.com" target="_blank" rel="noreferrer">https://status.openai.com</a></li></ul><h3 id="community" tabindex="-1">Community <a class="header-anchor" href="#community" aria-label="Permalink to &quot;Community&quot;">‚Äã</a></h3><ul><li>OpenAI Forum: <a href="https://community.openai.com" target="_blank" rel="noreferrer">https://community.openai.com</a></li><li>Discord: Official OpenAI community</li><li>Reddit: r/OpenAI</li></ul><h3 id="learning" tabindex="-1">Learning <a class="header-anchor" href="#learning" aria-label="Permalink to &quot;Learning&quot;">‚Äã</a></h3><ul><li>OpenAI Cookbook: Code examples</li><li>Prompt Engineering Guide: Best practices</li><li>Model documentation: Capabilities and limits</li></ul><h2 id="next-steps" tabindex="-1">Next Steps <a class="header-anchor" href="#next-steps" aria-label="Permalink to &quot;Next Steps&quot;">‚Äã</a></h2><ul><li>Configure your <a href="/docs/assistant/basics">Assistant</a> with OpenAI</li><li>Write effective <a href="/docs/assistant/prompts">Prompts</a> for GPT models</li><li>Explore <a href="/docs/assistant/custom-requests">Custom Requests</a> for advanced setups</li><li>Compare with other providers: <a href="/docs/providers/anthropic">Anthropic</a>, <a href="/docs/providers/google">Google</a></li></ul><p>Need help? Check the <a href="/docs/getting-started/faq">FAQ</a> or <a href="https://github.com/Chevey339/kelivo/issues" target="_blank" rel="noreferrer">open an issue</a>.</p></div></div></main><footer class="VPDocFooter" data-v-39a288b8 data-v-e257564d><!--[--><!--]--><div class="edit-info" data-v-e257564d><!----><div class="last-updated" data-v-e257564d><p class="VPLastUpdated" data-v-e257564d data-v-e98dd255>Last updated: <time datetime="2025-11-15T03:42:13.000Z" data-v-e98dd255></time></p></div></div><nav class="prev-next" aria-labelledby="doc-footer-aria-label" data-v-e257564d><span class="visually-hidden" id="doc-footer-aria-label" data-v-e257564d>Pager</span><div class="pager" data-v-e257564d><a class="VPLink link pager-link prev" href="/docs/assistant/mcp" data-v-e257564d><!--[--><span class="desc" data-v-e257564d>Previous page</span><span class="title" data-v-e257564d>MCP</span><!--]--></a></div><div class="pager" data-v-e257564d><a class="VPLink link pager-link next" href="/docs/providers/anthropic" data-v-e257564d><!--[--><span class="desc" data-v-e257564d>Next page</span><span class="title" data-v-e257564d>Anthropic</span><!--]--></a></div></nav></footer><!--[--><!--[--><!--[--><!--[--><!--]--><!--v-if--><!--[--><!--[--><!--]--><div class="tk-article-appreciation tk-article-appreciation--doc-after" aria-label="ÊñáÁ´†ËµûËµè"><button class="tk-article-appreciation__button" aria-expanded="false" aria-controls="tk-article-appreciation__content" aria-live="polite"><i class="tk-icon tk-article-appreciation__button__icon" style="--icon-size:16px;--icon-color-hover:var(--tk-theme-color);" aria-hidden="true"><svg
      t="1711730357270"
      class="icon"
      viewBox="0 0 1024 1024"
      version="1.1"
      xmlns="http://www.w3.org/2000/svg"
      p-id="4392"
      width="16"
      height="16"
    >
      <path
        fill="currentColor"
        d="M512 1024a512 512 0 1 1 512-512 512 512 0 0 1-512 512z m-112.523636-836.538182c-144.989091 0-262.516364 100.538182-262.516364 224.465455 0 74.007273 42.123636 139.636364 106.705455 180.363636l-19.549091 78.312727 86.807272-47.592727a301.265455 301.265455 0 0 0 88.669091 13.381818h2.210909a178.967273 178.967273 0 0 1-3.607272-34.909091c0-115.083636 109.498182-208.407273 244.363636-208.407272 6.167273 0 11.636364 0 18.152727 0.814545-10.589091-115.665455-123.461818-206.778182-261.469091-206.778182z m246.690909 226.443637c-124.741818 0-225.861818 86.109091-225.861818 192.465454s101.003636 192.349091 225.861818 192.349091a257.047273 257.047273 0 0 0 99.723636-20.014545l77.265455 40.610909L802.909091 744.727273a179.316364 179.316364 0 0 0 69.003636-138.24c0-106.24-101.12-192.465455-225.861818-192.465455z m81.454545 152.087272a31.767273 31.767273 0 1 1 32.349091-31.767272 32 32 0 0 1-32.349091 31.767272z m-164.072727 0a31.767273 31.767273 0 1 1 32.349091-31.767272 32 32 0 0 1-32.349091 31.767272zM502.341818 373.527273a34.909091 34.909091 0 1 1 34.909091-34.909091 34.909091 34.909091 0 0 1-34.909091 34.909091z m-206.196363 0a34.909091 34.909091 0 1 1 34.90909-34.909091 34.909091 34.909091 0 0 1-34.90909 34.909091z m0 0"
        p-id="4393"
      />
    </svg></i><span>ÊâìËµèÊîØÊåÅ</span></button><!--v-if--></div><!--[--><!--]--><!--]--><!-- ËØÑËÆ∫Âå∫ --><!--v-if--><!--]--><!--]--><!--]--></div></div></div><!--[--><!--]--></div></div><!----><!--[--><!--]--></div><!--]--></div>
    
    
  </body>
</html>